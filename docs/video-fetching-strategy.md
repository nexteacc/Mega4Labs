# 视频抓取策略与系统架构文档

本文档详细记录了 Mega 4 Labs 视频抓取系统的设计理念、核心流程、增量更新机制及成本控制策略。

## 1. 核心设计理念

本系统旨在从海量网络信息中精准挖掘 AI 领域领袖的高质量长视频（访谈、演讲），并以极低成本实现自动化维护。设计遵循以下原则：

*   **分层处理 (Layered Processing)**：将“发现”、“补全”、“验证”解耦，利用不同工具的优势。
*   **增量优先 (Incremental First)**：利用本地历史数据动态调整搜索范围，避免重复劳动。
*   **成本极简 (Cost Minimization)**：Exa 仅做索引，YouTube API 承担元数据，LLM 仅做最后一道把关。

---

## 2. 详细工作流程

系统执行逻辑主要包含三个阶段：

### 阶段一：智能发现 (Discovery) - Exa AI
*   **目标**：获取可能包含目标人物视频的 YouTube 链接。
*   **策略**：使用 Exa 的 Neural Search 能力，但不请求网页内容（Contents），仅获取 URL。
*   **配置**：
    *   `includeDomains`: `["youtube.com"]`
    *   `numResults`: 增量模式下 **10条** / 全量模式下 **20条**。
    *   `startPublishedDate`: 动态计算（详见下文“增量机制”）。

### 阶段二：元数据补全 (Metadata Enrichment) - YouTube Data API
*   **目标**：获取视频的精准元数据（标题、发布时间、时长、频道）。
*   **优势**：相比网页爬取，官方 API 数据结构化程度高，且完全免费（在配额内）。
*   **硬过滤规则 (Hard Filters)**：
    1.  **去重**：Video ID 已存在于本地数据库则直接丢弃。
    2.  **时长过滤**：`duration < 5分钟` 直接丢弃（排除 Shorts、预告片、新闻快讯）。
    3.  **时间过滤**：发布时间早于本地最新记录的视频丢弃。

### 阶段三：价值验证 (Verification) - LLM (Gemini)
*   **目标**：判断视频是否为目标人物的“核心内容”（访谈、演讲），排除由于名字匹配导致的误报（如“提到”某人而非“本人出演”）。
*   **输入**：视频标题、截断后的描述（前500字符）、频道名。
*   **操作**：按人物批量发送给 Gemini 进行 True/False 判别。
*   **输出**：仅将 `isRelevant: true` 的视频写入 `src/data/videos.json`。

---

## 3. 增量更新与时间窗口机制

为了实现“每周运行”且“不漏数据”，我们设计了动态时间窗口算法。

### 算法逻辑
1.  **读取历史**：脚本启动时，扫描 `src/data/videos.json`。
2.  **定位锚点**：针对每个搜索对象（如 "Sam Altman"），找到已入库视频中**发布时间最晚**的日期 `LatestDate`。
3.  **计算起点**：设置 Exa 搜索起点 `startPublishedDate` = `LatestDate` - **30天**。
4.  **安全缓冲 (Safety Buffer)**：
    *   **为什么减30天？** 即使视频是上周发布的，Exa 的索引可能存在数天的延迟。此外，有时旧视频会因为热度上升被重新发现。30天缓冲确保了即使每周运行一次，也不会因为时间卡得太死而漏掉边缘数据。

---

## 4. 运行配置与决策记录

### GitHub Actions 配置
*   **文件**：`.github/workflows/update-videos.yml`
*   **频率**：`cron: '0 2 * * 1'`（每周一 UTC 02:00 / 北京时间 10:00）。
*   **理由**：AI 领袖的长访谈视频产出频率较低（通常月更或季更），每周一次足以覆盖，且大幅降低 API 调用和计算资源消耗。

### 搜索结果数量 (Max Results) 决策
*   **全量模式 (`--full`)**：`maxResults: 20`
    *   用于初始化或手动强制深挖。
*   **增量模式 (默认)**：`maxResults: 10`
    *   **理由**：在每周运行且有30天回溯的前提下，单个人物一周内产出超过 10 个高质量长视频的概率极低。将上限压低可以显著减少 LLM 的 Token 消耗，同时通过高频（相对视频产出率）的扫描保证覆盖。

---

## 5. 成本模型推演

| 环节 | 旧方案 (Search+Content) | **新方案 (Search Only + API)** | 降幅 |
| :--- | :--- | :--- | :--- |
| **Exa** | 搜索+爬取内容费 (高) | 仅基础搜索费 (极低) | **>90%** |
| **Metadata** | 不准确/需额外爬虫 | YouTube API (免费配额) | **100%** (Free) |
| **LLM** | 全量验证，包含短视频 | 仅验证时长>5min的**新增**视频 | **>80%** |

*   **YouTube Quota**：`videos.list` 消耗 1 unit/次。每日限额 10,000 units。每周运行消耗 < 500 units，完全免费。
*   **Token Saving**：通过 YouTube API 精准的时长字段，在进入 LLM 之前就过滤掉了大量无效短视频，大幅节省 Token。
