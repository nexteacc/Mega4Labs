# 视频陪读（Video Sidekick）功能规格（MVP → 可扩展）

本文档记录“对长视频进行总结/挖掘，并在播放时提供陪读体验”的产品功能与最小可行实现方案。核心原则：结构优先（结构、结构、结构）。

---

## 1. 背景与问题定义

用户在观看长视频（访谈/演讲）时，主要痛点不是“看不懂”，而是：

*   不知道自己当前在视频里“讲到哪了”
*   记不清前面“聊过什么话题 / 问过什么问题 / 得出什么结论”
*   想快速回到某个关键片段，但缺少可导航结构

因此，本功能的核心不是“做一个复杂的内容平台”，而是把视频内容抽象为可导航结构，并在运行时将结构与时间轴拼装成陪读视图。

---

## 2. 两类结构（避免走偏）

### 结构 A：陪读结构（运行时）

*   **目标**：用户此刻在看，立刻知道“我在哪、前面聊啥、刚问了啥答了啥”
*   **输出**：`Now / Context / Recent QAs`
*   **来源**：从“内容结构（离线）”按当前播放时间裁切与拼装

### 结构 B：内容结构（离线）

*   **目标**：模型把整期视频挖掘成话题、问题、结论、例子（可复用/可检索）
*   **输出**：`Topics（带子节点 QA / Takeaways）`，每个节点带时间戳范围
*   **用途**：
    *   运行时驱动陪读 UI
    *   离线检索/复盘（后续功能）

---

## 3. 核心数据结构（T/Q/A + 时间戳）

最小结构定义为三层：**话题（Topic）—问题（Question）—答案要点（Answer bullets）**，并且必须绑定时间范围（秒）。

### 3.1 内容结构（离线）建议 Schema（MVP）

```json
{
  "videoId": "string",
  "language": "string",
  "generatedAt": "ISO-8601",
  "segments": [
    {
      "topic": "2-4 words",
      "timestamp": { "start": 120, "end": 420 },
      "question": "string",
      "answer": ["string", "string", "string"],
      "takeaways": ["string", "string"]
    }
  ]
}
```

说明：

*   `segments` 为按时间顺序排列的卡片流（Topic Card Stream），避免“章节式大纲”带来的冗余与跳跃。
*   `takeaways` 可选，但对 UI 的“快速结论”很有价值；若 MVP 要极简，可暂不输出。

### 3.2 陪读结构（运行时）建议 Schema（派生）

运行时从 `segments` 派生：

```json
{
  "now": { "segmentIndex": 7, "topic": "Pricing", "t": 1337 },
  "context": [
    { "segmentIndex": 5, "topic": "Product", "timestamp": { "start": 900, "end": 1100 } },
    { "segmentIndex": 6, "topic": "Distribution", "timestamp": { "start": 1100, "end": 1280 } }
  ],
  "recentQAs": [
    { "segmentIndex": 7, "question": "Why now?", "answer": ["..."] }
  ]
}
```

---

## 4. UI 设计（右侧陪读面板）

### 4.1 面板目标（MVP）

右侧面板只解决三件事：

*   **定位**：当前在讲哪个话题（Now）
*   **回忆**：前面刚讲过哪些话题（Context）
*   **对话**：刚问了什么、怎么答的（Recent QAs）

### 4.2 交互（MVP）

*   **点击跳转**：点击任一卡片 → 播放器跳到该卡片的 `timestamp.start`
*   **磁吸高亮**：播放时间进入某卡片区间 → 右侧自动高亮该卡片（并可自动滚动到视口内）
*   **追问输入**：输入框“就当前卡片提问”，返回答案要点（可选：引用时间范围）

### 4.3 运行时渲染逻辑

给定当前播放时间 `t`：

*   `Now`：找到满足 `start <= t < end` 的 segment（若无，则取最近的前一个）
*   `Context`：取 `Now` 之前 N 个 segment（例如 2～4 个）
*   `Recent QAs`：取 `Now` 及最近若干条（例如 1～3 条）

---

## 5. MVP：简单生成策略（不搞复杂识别）

### 5.1 核心驱动（建议）

**字幕 + 滑动窗口 + 一次模型调用**（离线生成结构 B；运行时只做裁切拼装结构 A）。

*   输入：带时间戳的字幕片段（例如 `[120s]: ...`）
*   模型任务：
    1. 按话题切段（3–5 分钟粒度，话题变了就新卡片）
    2. 为每段输出：Topic / start-end 秒 / Question / Answer bullets（可选 Takeaways）
*   输出：`segments[]`（可持久化）

### 5.2 为什么 MVP 不做“复杂互动识别”

*   说话人识别、情绪/立场识别、角色扮演等，会把讨论引向“识别准确率”而不是“陪读是否有效”
*   MVP 只要结构能驱动“定位 + 回忆 + 跳转”，就能验证主要价值

---

## 6. 数据源与字幕获取（方案讨论摘要）

字幕是时间戳对齐的关键。按“速度/合规/覆盖”权衡有四类路径：

### 6.1 路径 A：非官方字幕抓取（快）

*   优点：实现最快，适合验证 UI/结构闭环
*   风险：稳定性与合规性不可保证，可能遇到无字幕/地区/登录限制

### 6.2 路径 B：官方能力（稳/合规）

*   优点：长期可产品化、合规与稳定性最好
*   限制：对“任意公开视频”可用性不一定成立（权限/配额/数据能力约束）

### 6.3 路径 C：下载器/自动化（覆盖强但风险高）

*   优点：覆盖面大
*   风险：合规/风控/运维成本高，不适合作为长期产品主路径

### 6.4 路径 D：直接多模态读视频（成本高）

*   优点：不依赖字幕抓取
*   缺点：成本与时戳精度通常不理想，长视频受限

---

## 7. 非目标（MVP 明确不做）

*   不做“章节式长大纲”或“全片时间线摘要墙”
*   不做高精度说话人分离、情绪/立场分类、自动角色扮演
*   不做复杂的检索系统与知识库（可作为后续）

---

## 8. 风险与降级策略

*   **无字幕/取字幕失败**：降级为“无时间戳的主题/QA”（仍可显示，但不能精确跳转）
*   **时间戳漂移**：允许卡片级别误差，但必须保持“片段内自洽”（start-end 不乱跳）
*   **长视频 token 超限**：字幕裁切或分段聚合（先按窗口压缩，再做一次全局切段）
*   **合规风险**：探索期与产品化路径分离；上线前切换到可合规的数据获取策略

---

## 9. 里程碑与验收（建议）

### 9.1 MVP 验收标准

*   任意一条长视频能生成 `segments[]`（Topic/Q/A + 秒级范围）
*   播放时右侧面板能稳定显示 `Now/Context/Recent QAs`
*   点击卡片可跳转；播放推进可自动高亮（双向同步）

### 9.2 可扩展方向（后续）

*   `takeaways/examples` 结构增强
*   卡片检索与跨视频复用
*   更细粒度的 QA 生成（围绕用户追问）

